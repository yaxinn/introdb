package org.apache.spark.sql.execution.joins.dns

import java.util.{HashMap => JavaHashMap, ArrayList => JavaArrayList}
import java.util.concurrent.ConcurrentHashMap

import org.apache.spark.sql.Row
import org.apache.spark.sql.catalyst.expressions.{JoinedRow, Projection, Expression}
import org.apache.spark.sql.execution.SparkPlan

/**
 * In this join, we are going to implement an algorithm similar to symmetric hash join.
 * However, instead of being provided with two input relations, we are instead going to
 * be using a single dataset and obtaining the other data remotely -- in this case by
 * asynchronous HTTP requests.
 *
 * The dataset that we are going to focus on reverse DNS, latitude-longitude lookups.
 * That is, given an IP address, we are going to try to obtain the geographical
 * location of that IP address. For this end, we are going to use a service called
 * telize.com, the owner of which has graciously allowed us to bang on his system.
 *
 * For that end, we have provided a simple library that makes asynchronously makes
 * requests to telize.com and handles the responses for you. You should read the
 * documentation and method signatures in DNSLookup.scala closely before jumping into
 * implementing this.
 *
 * The algorithm will work as follows:
 * We are going to be a bounded request buffer -- that is, we can only have a certain number
 * of unanswered requests at a certain time. When we initialize our join algorithm, we
 * start out by filling up our request buffer. On a call to next(), you should take all
 * the responses we have received so far and materialize the results of the join with those
 * responses and return those responses, until you run out of them. You then materialize
 * the next batch of joined responses until there are no more input tuples, there are no
 * outstanding requests, and there are no remaining materialized rows.
 *
 */
trait DNSJoin {
  self: SparkPlan =>

  val leftKeys: Seq[Expression]
  val left: SparkPlan

  override def output = left.output

  @transient protected lazy val leftKeyGenerator: Projection =
    newProjection(leftKeys, left.output)

  // How many outstanding requests we can have at once.
  val requestBufferSize: Int = 300

  /**
   * The main logic for DNS join. You do not need to implement anything outside of this method.
   * This method takes in an input iterator of IP addresses and returns a joined row with the location
   * data for each IP address.
   *
   * If you find the method definitions provided to be counter-intuitive or constraining, feel free to change them.
   * However, note that if you do:
   *  1. we will have a harder time helping you debug your code.
   *  2. Iterators must implement next and hasNext. If you do not implement those two methods, your code will not compile.
   *
   * **NOTE**: You should return JoinedRows, which take two input rows and returns the concatenation of them.
   * e.g., `new JoinedRow(row1, row2)`
   *
   * @param input the input iterator
   * @return the result of the join
   */
  def hashJoin(input: Iterator[Row]): Iterator[Row] = {
    new Iterator[Row] {
      // IMPLEMENT ME
      var reqBuffer = new ConcurrentHashMap[Int, Row]()
      var respBuffer = new ConcurrentHashMap[Int, Row]()
      var respCache = new JavaHashMap[Row, Row]()
      var requests = new JavaArrayList[Row]()
      
      var reqNum: Int = 0
      var inputRow: Row = null
      var idx: Int = 0

      while (input.hasNext && reqNum < requestBufferSize ) {
        inputRow = input.next()
        if (!requests.contains(inputRow)){
          makeRequest()
          reqNum += 1
        }
        requests.add(inputRow)
      }
      
      /**
       * This method returns the next joined tuple.
       *
       * *** THIS MUST BE IMPLEMENTED FOR THE ITERATOR TRAIT ***
       */
      override def next() = {
        // IMPLEMENT ME
        var key = leftKeyGenerator.apply (requests.get(idx))

        if (respCache.size() > 0 && respCache.containsKey(key)) {
          idx += 1
          respCache.get(key)
        }
        else {
          // busy waiting
          while ( reqBuffer.size() != respBuffer.size()) {}

          var respIter = respBuffer.keySet().iterator()
          
          while (respIter.hasNext) {
            var bKey = respIter.next()
            var response = respBuffer.get(bKey)
            var request = reqBuffer.get(bKey)

            respCache.put(leftKeyGenerator.apply(request), new JoinedRow(request, response))

            reqBuffer.remove(bKey)
            respBuffer.remove(bKey)

            // fetch next input
            if (input.hasNext) {
              inputRow = input.next()
              // make a new request only if we haven't already made one
              if (!requests.contains(inputRow)){ 
                reqNum = bKey
                requests.add(inputRow)
                makeRequest()
              }
            }
          }
          if (respCache.containsKey(key)) {
            idx += 1
            respCache.get(key)
          }
          else null
        }

      }

      /**
       * This method returns whether or not this iterator has any data left to return.
       *
       * *** THIS MUST BE IMPLEMENTED FOR THE ITERATOR TRAIT ***
       */
      override def hasNext() = {
        // IMPLEMENT ME
        idx < requests.size()
      }


      /**
       * This method takes the next element in the input iterator and makes an asynchronous request for it.
       */
      private def makeRequest() = {
        // IMPLEMENT ME
        var ip = inputRow.getString(0)
        reqBuffer.put(reqNum, inputRow)
        DNSLookup.lookup(reqNum, ip, respBuffer, reqBuffer)
      }
    }
  }
}
